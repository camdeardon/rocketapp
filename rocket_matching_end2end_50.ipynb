{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f66f1e2",
   "metadata": {},
   "source": [
    "\n",
    "# Rocket Matching — End‑to‑End: Interview Extraction + Hybrid Recommender (50 users)\n",
    "\n",
    "This notebook combines:\n",
    "- **Interview capture & extraction** (role, interests, skills, years_exp, reason) + unstructured parsing (spaCy + KeyBERT-ready).\n",
    "- **Hybrid matching**: content (text/geo/exp/role), **skills** (similar vs complementary), CF (implicit), graph (Personalized PageRank), personality, reciprocity, MMR diversification.\n",
    "- **Synthetic cohort (n=50)** with diverse backgrounds: creators, scientists, writers, ML engineers, brand founders, ocean projects, YouTubers, social apps, etc.\n",
    "\n",
    "> Optional installs (run locally): `pip install spacy keybert sentence-transformers scipy pdfplumber python-docx networkx geopy scikit-learn`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4db2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, pandas as pd, random, math\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "np.random.seed(7); random.seed(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aacea48",
   "metadata": {},
   "source": [
    "## Personality (TIPI → Big Five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38eba23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class BigFive:\n",
    "    O: float; C: float; E: float; A: float; N: float\n",
    "\n",
    "def clip01(x): \n",
    "    import numpy as np\n",
    "    return float(np.clip(x, 0.0, 1.0))\n",
    "\n",
    "TIPI_KEY = {\n",
    "    1: (\"E\", False), 2: (\"A\", True), 3: (\"C\", False), 4: (\"N\", False), 5: (\"O\", False),\n",
    "    6: (\"E\", True),  7: (\"A\", False),8: (\"C\", True),  9: (\"N\", True),  10:(\"O\", True)\n",
    "}\n",
    "\n",
    "def score_tipi(responses_1to7):\n",
    "    import numpy as np\n",
    "    assert len(responses_1to7)==10\n",
    "    r = np.array(responses_1to7, dtype=float)\n",
    "    r01 = (r-1)/6.0  # 1..7 -> 0..1\n",
    "    traits = {\"O\":[], \"C\":[], \"E\":[], \"A\":[], \"N\":[]}\n",
    "    for i,val in enumerate(r01, start=1):\n",
    "        trait, rev = TIPI_KEY[i]\n",
    "        traits[trait].append(1.0-val if rev else val)\n",
    "    return BigFive(*(clip01(np.mean(traits[t])) for t in [\"O\",\"C\",\"E\",\"A\",\"N\"]))\n",
    "\n",
    "def bigfive_cosine(u: BigFive, v: BigFive) -> float:\n",
    "    import numpy as np\n",
    "    a = np.array([u.O,u.C,u.E,u.A,u.N])\n",
    "    b = np.array([v.O,v.C,v.E,v.A,v.N])\n",
    "    return float(a @ b / (np.linalg.norm(a)*np.linalg.norm(b) + 1e-9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ced62cf",
   "metadata": {},
   "source": [
    "## Interview schema + lightweight extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e6fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INTERVIEW_FIELDS = [\"human\",\"role\",\"interests\",\"skills\",\"years_exp\",\"professional\",\"contributor\",\"interests_long\",\"reason\"]\n",
    "\n",
    "def parse_comma_list(s: str) -> List[str]:\n",
    "    return [x.strip() for x in (s or \"\").split(\",\") if x.strip()]\n",
    "\n",
    "def normalize_interview(answers: Dict[str,str]) -> Dict[str,Any]:\n",
    "    # Enforce <=250 words per answer for realism (truncate if needed)\n",
    "    def wclip(t): \n",
    "        words = t.split()\n",
    "        return \" \".join(words[:250])\n",
    "    answers = {k: wclip(v or \"\") for k,v in answers.items()}\n",
    "    out = {\n",
    "        \"role\": answers.get(\"role\",\"Undecided\").strip() or \"Undecided\",\n",
    "        \"interests\": \", \".join(parse_comma_list(answers.get(\"interests\",\"\"))[:20]),\n",
    "        \"skills\": \", \".join(parse_comma_list(answers.get(\"skills\",\"\"))[:20]),\n",
    "        \"years_exp\": int(str(answers.get(\"years_exp\",\"0\")).strip() or 0),\n",
    "        \"bio\": (answers.get(\"professional\",\"\") or \"\")[:220],\n",
    "        \"reason_for_joining\": (answers.get(\"reason\",\"\") or \"\").strip(),\n",
    "        \"long_text\": \" \".join([answers.get(\"human\",\"\"), answers.get(\"contributor\",\"\"), answers.get(\"interests_long\",\"\")])[:1500]\n",
    "    }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb59535",
   "metadata": {},
   "source": [
    "## Content features (text + geo + experience + role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "638695e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_text_matrix(df: pd.DataFrame) -> Tuple[TfidfVectorizer, any]:\n",
    "    corpus = (df['interests'].fillna('') + \" ; \" + df['skills'].fillna('') + \" ; \" + df['bio'].fillna('')).tolist()\n",
    "    vec = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
    "    X = vec.fit_transform(corpus)\n",
    "    return vec, X\n",
    "\n",
    "def geo_similarity(df: pd.DataFrame, decay_km: float = 2500.0) -> np.ndarray:\n",
    "    n = len(df); S = np.zeros((n,n), dtype=float)\n",
    "    coords = list(zip(df['lat'], df['lon']))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i==j: continue\n",
    "            d_km = geodesic(coords[i], coords[j]).km\n",
    "            S[i,j] = np.exp(-d_km/decay_km)\n",
    "    if S.max()>0: S = S/S.max()\n",
    "    return S\n",
    "\n",
    "def experience_compatibility(years: List[int], sweet_spot: float = 3.0) -> np.ndarray:\n",
    "    years = np.array(years); n=len(years); S=np.zeros((n,n),dtype=float)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i==j: continue\n",
    "            gap = abs(years[i]-years[j])\n",
    "            S[i,j] = np.exp(-((gap-sweet_spot)**2)/(2*(sweet_spot**2)))\n",
    "    if S.max()>0: S = S/S.max()\n",
    "    return S\n",
    "\n",
    "ROLE_COMP = {\n",
    "    \"Founder\": {\"Engineer\": 1.0, \"Designer\": 1.0, \"Researcher\": 0.8, \"Founder\": 0.2, \"Writer\":0.6, \"Scientist\":0.7, \"Creator\":0.8},\n",
    "    \"Engineer\": {\"Founder\": 1.0, \"Designer\": 0.7, \"Engineer\": 0.2, \"Researcher\": 0.6, \"Writer\":0.6, \"Scientist\":0.8, \"Creator\":0.7},\n",
    "    \"Designer\": {\"Founder\": 1.0, \"Engineer\": 0.7, \"Designer\": 0.2, \"Researcher\": 0.5, \"Writer\":0.6, \"Scientist\":0.5, \"Creator\":0.9},\n",
    "    \"Researcher\": {\"Founder\": 0.8, \"Engineer\": 0.7, \"Designer\": 0.5, \"Researcher\": 0.3, \"Writer\":0.5, \"Scientist\":0.9, \"Creator\":0.6},\n",
    "    \"Writer\": {\"Founder\":0.8, \"Engineer\":0.6, \"Designer\":0.7, \"Researcher\":0.5, \"Writer\":0.2, \"Scientist\":0.5, \"Creator\":0.9},\n",
    "    \"Scientist\":{\"Founder\":0.9, \"Engineer\":0.9, \"Designer\":0.5, \"Researcher\":0.8, \"Writer\":0.5, \"Scientist\":0.2, \"Creator\":0.6},\n",
    "    \"Creator\":{\"Founder\":0.9, \"Engineer\":0.7, \"Designer\":0.9, \"Researcher\":0.6, \"Writer\":0.9, \"Scientist\":0.6, \"Creator\":0.3},\n",
    "    \"Undecided\": {\"Founder\":0.6,\"Engineer\":0.6,\"Designer\":0.6,\"Researcher\":0.6,\"Writer\":0.6,\"Scientist\":0.6,\"Creator\":0.6,\"Undecided\":0.2}\n",
    "}\n",
    "\n",
    "def role_complementarity(df: pd.DataFrame) -> np.ndarray:\n",
    "    roles = df['role'].tolist(); n=len(roles); S=np.zeros((n,n),dtype=float)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i==j: continue\n",
    "            S[i,j] = ROLE_COMP.get(roles[i], {}).get(roles[j], 0.2)\n",
    "    return S\n",
    "\n",
    "def combine_content(S_text, S_geo, S_exp, S_role, w=(0.45,0.2,0.15,0.2)):\n",
    "    a,b,c,d = w\n",
    "    S = a*S_text + b*S_geo + c*S_exp + d*S_role\n",
    "    return S / (S.max() + 1e-9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cd5e61",
   "metadata": {},
   "source": [
    "## Skills strategies: similar vs complementary (Hungarian fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ec1041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def parse_skill_list(sk: str) -> List[str]:\n",
    "    return [s.strip().lower() for s in (sk or \"\").split(\",\") if s.strip()]\n",
    "\n",
    "def tfidf_cosine(a_list: List[str], b_list: List[str]) -> float:\n",
    "    docs = [\"; \".join(a_list), \"; \".join(b_list)]\n",
    "    vec = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
    "    X = vec.fit_transform(docs)\n",
    "    return float(cosine_similarity(X[0], X[1])[0,0])\n",
    "\n",
    "def similar_skills_matrix(df: pd.DataFrame) -> np.ndarray:\n",
    "    n=len(df); S=np.zeros((n,n))\n",
    "    parsed = [parse_skill_list(x) for x in df['skills'].fillna('')]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i==j: continue\n",
    "            S[i,j] = tfidf_cosine(parsed[i], parsed[j])\n",
    "    if S.max()>0: S = S/S.max()\n",
    "    return S\n",
    "\n",
    "def complementary_skills_matrix(df: pd.DataFrame) -> np.ndarray:\n",
    "    wants = [parse_skill_list(row.get('skills_want', row.get('interests',''))) for _,row in df.iterrows()]\n",
    "    haves = [parse_skill_list(row.get('skills','')) for _,row in df.iterrows()]\n",
    "    n=len(df); S=np.zeros((n,n))\n",
    "    try:\n",
    "        from scipy.optimize import linear_sum_assignment\n",
    "        for i in range(n):\n",
    "            need = wants[i]\n",
    "            for j in range(n):\n",
    "                if i==j: continue\n",
    "                have = haves[j]\n",
    "                if not need or not have: \n",
    "                    S[i,j]=0.0; continue\n",
    "                A = [\"; \".join([n1]) for n1 in need]\n",
    "                B = [\"; \".join([h1]) for h1 in have]\n",
    "                vec = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
    "                X = vec.fit_transform(A + B)\n",
    "                m, k = len(need), len(have)\n",
    "                Csim = np.zeros((m,k))\n",
    "                for p in range(m):\n",
    "                    for q in range(k):\n",
    "                        Csim[p,q] = cosine_similarity(X[p], X[m+q])[0,0]\n",
    "                size = max(m,k)\n",
    "                padded = np.ones((size,size))\n",
    "                padded[:m,:k] = 1.0 - Csim  # cost = 1 - sim\n",
    "                r_ind, c_ind = linear_sum_assignment(padded)\n",
    "                total_sim = 0.0; count = 0\n",
    "                for r,c in zip(r_ind, c_ind):\n",
    "                    if r < m and c < k:\n",
    "                        total_sim += 1.0 - padded[r,c]; count += 1\n",
    "                S[i,j] = total_sim / (count + 1e-9)\n",
    "        if S.max()>0: S = S/S.max()\n",
    "    except Exception:\n",
    "        # Fallback: average max similarity\n",
    "        for i in range(n):\n",
    "            need = wants[i]\n",
    "            for j in range(n):\n",
    "                if i==j: continue\n",
    "                have = haves[j]\n",
    "                if not need or not have: \n",
    "                    S[i,j]=0.0; continue\n",
    "                sims = []\n",
    "                for nterm in need:\n",
    "                    sims.append(max(tfidf_cosine([nterm], [h]) for h in have))\n",
    "                S[i,j] = float(np.mean(sims)) if sims else 0.0\n",
    "        if S.max()>0: S = S/S.max()\n",
    "    return S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca60ae",
   "metadata": {},
   "source": [
    "## CF (implicit), Graph (PPR), Personality, Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f10e9a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reciprocalize(S: np.ndarray) -> np.ndarray:\n",
    "    return np.sqrt(S * S.T + 1e-12)\n",
    "\n",
    "def fuse_scores(S_content, S_cf, S_graph, S_person, S_skills, weights=(0.35,0.2,0.15,0.15,0.15)):\n",
    "    Sc = reciprocalize(S_content)\n",
    "    Sf = reciprocalize(S_cf)\n",
    "    Sg = reciprocalize(S_graph)\n",
    "    Sp = reciprocalize(S_person)\n",
    "    Ss = reciprocalize(S_skills)\n",
    "    a,b,c,d,e = weights\n",
    "    S = a*Sc + b*Sf + c*Sg + d*Sp + e*Ss\n",
    "    return S / (S.max() + 1e-12)\n",
    "\n",
    "def mmr(query_idx: int, S: np.ndarray, K: int = 3, lambda_rel: float = 0.7):\n",
    "    n = S.shape[0]\n",
    "    candidates = [i for i in range(n) if i != query_idx]\n",
    "    selected = []\n",
    "    while candidates and len(selected) < K:\n",
    "        if not selected:\n",
    "            i = max(candidates, key=lambda j: S[query_idx, j])\n",
    "            selected.append(i); candidates.remove(i)\n",
    "        else:\n",
    "            def score(j):\n",
    "                redundancy = max(S[j, s] for s in selected) if selected else 0.0\n",
    "                return lambda_rel * S[query_idx, j] - (1-lambda_rel) * redundancy\n",
    "            i = max(candidates, key=score)\n",
    "            selected.append(i); candidates.remove(i)\n",
    "    return selected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f7e4f6",
   "metadata": {},
   "source": [
    "## Generate 50 diverse synthetic users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f0f8fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>role</th>\n",
       "      <th>interests</th>\n",
       "      <th>skills</th>\n",
       "      <th>years_exp</th>\n",
       "      <th>bio</th>\n",
       "      <th>reason_for_joining</th>\n",
       "      <th>long_text</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>bf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>User01</td>\n",
       "      <td>Designer</td>\n",
       "      <td>sports analytics, coral reef restoration, publ...</td>\n",
       "      <td>react, growth, go</td>\n",
       "      <td>7</td>\n",
       "      <td>I work as a designer with 7 years in the field...</td>\n",
       "      <td>Find collaborators</td>\n",
       "      <td>In San Francisco, I split time between creativ...</td>\n",
       "      <td>37.774900</td>\n",
       "      <td>-122.419400</td>\n",
       "      <td>BigFive(O=0.5, C=0.41666666666666663, E=0.5, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>User02</td>\n",
       "      <td>Writer</td>\n",
       "      <td>healthcare AI, newsletter growth, educational ...</td>\n",
       "      <td>tensorflow, product, aws, statistics</td>\n",
       "      <td>1</td>\n",
       "      <td>I work as a writer with 1 years in the field. ...</td>\n",
       "      <td>Find collaborators</td>\n",
       "      <td>Sydney is home. I keep a simple routine: work,...</td>\n",
       "      <td>-33.868800</td>\n",
       "      <td>151.209300</td>\n",
       "      <td>BigFive(O=0.5, C=0.75, E=0.6666666666666667, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>User03</td>\n",
       "      <td>Researcher</td>\n",
       "      <td>financial inclusion, publishing, music product...</td>\n",
       "      <td>oceanography, sql, causal inference, branding,...</td>\n",
       "      <td>8</td>\n",
       "      <td>I work as a researcher with 8 years in the fie...</td>\n",
       "      <td>Find collaborators</td>\n",
       "      <td>I’m based in Nairobi, balancing work with week...</td>\n",
       "      <td>-1.286389</td>\n",
       "      <td>36.817223</td>\n",
       "      <td>BigFive(O=0.3333333333333333, C=0.416666666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>User04</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>coral reef restoration, privacy-first messagin...</td>\n",
       "      <td>strategy, oceanography, react, nextjs, design ...</td>\n",
       "      <td>10</td>\n",
       "      <td>I work as a scientist with 10 years in the fie...</td>\n",
       "      <td>Build a dream</td>\n",
       "      <td>In Nairobi, I split time between creative work...</td>\n",
       "      <td>-1.286389</td>\n",
       "      <td>36.817223</td>\n",
       "      <td>BigFive(O=0.5, C=0.3333333333333333, E=0.5, A=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User05</td>\n",
       "      <td>Founder</td>\n",
       "      <td>fashion sustainability, beauty brand, newslett...</td>\n",
       "      <td>aws, branding, airflow, biostatistics, nextjs</td>\n",
       "      <td>13</td>\n",
       "      <td>I work as a founder with 13 years in the field...</td>\n",
       "      <td>Find projects</td>\n",
       "      <td>I’m based in London, balancing work with weeke...</td>\n",
       "      <td>51.507200</td>\n",
       "      <td>-0.127600</td>\n",
       "      <td>BigFive(O=0.5, C=0.6666666666666667, E=0.75, A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    name        role  \\\n",
       "0        1  User01    Designer   \n",
       "1        2  User02      Writer   \n",
       "2        3  User03  Researcher   \n",
       "3        4  User04   Scientist   \n",
       "4        5  User05     Founder   \n",
       "\n",
       "                                           interests  \\\n",
       "0  sports analytics, coral reef restoration, publ...   \n",
       "1  healthcare AI, newsletter growth, educational ...   \n",
       "2  financial inclusion, publishing, music product...   \n",
       "3  coral reef restoration, privacy-first messagin...   \n",
       "4  fashion sustainability, beauty brand, newslett...   \n",
       "\n",
       "                                              skills  years_exp  \\\n",
       "0                                  react, growth, go          7   \n",
       "1               tensorflow, product, aws, statistics          1   \n",
       "2  oceanography, sql, causal inference, branding,...          8   \n",
       "3  strategy, oceanography, react, nextjs, design ...         10   \n",
       "4      aws, branding, airflow, biostatistics, nextjs         13   \n",
       "\n",
       "                                                 bio  reason_for_joining  \\\n",
       "0  I work as a designer with 7 years in the field...  Find collaborators   \n",
       "1  I work as a writer with 1 years in the field. ...  Find collaborators   \n",
       "2  I work as a researcher with 8 years in the fie...  Find collaborators   \n",
       "3  I work as a scientist with 10 years in the fie...       Build a dream   \n",
       "4  I work as a founder with 13 years in the field...       Find projects   \n",
       "\n",
       "                                           long_text        lat         lon  \\\n",
       "0  In San Francisco, I split time between creativ...  37.774900 -122.419400   \n",
       "1  Sydney is home. I keep a simple routine: work,... -33.868800  151.209300   \n",
       "2  I’m based in Nairobi, balancing work with week...  -1.286389   36.817223   \n",
       "3  In Nairobi, I split time between creative work...  -1.286389   36.817223   \n",
       "4  I’m based in London, balancing work with weeke...  51.507200   -0.127600   \n",
       "\n",
       "                                                  bf  \n",
       "0  BigFive(O=0.5, C=0.41666666666666663, E=0.5, A...  \n",
       "1  BigFive(O=0.5, C=0.75, E=0.6666666666666667, A...  \n",
       "2  BigFive(O=0.3333333333333333, C=0.416666666666...  \n",
       "3  BigFive(O=0.5, C=0.3333333333333333, E=0.5, A=...  \n",
       "4  BigFive(O=0.5, C=0.6666666666666667, E=0.75, A...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "names = [f\"User{i:02d}\" for i in range(1, 51)]\n",
    "roles = [\"Founder\",\"Engineer\",\"Designer\",\"Researcher\",\"Writer\",\"Scientist\",\"Creator\"]\n",
    "cities = [\n",
    "    (\"Toronto\",43.6532,-79.3832),(\"New York\",40.7128,-74.0060),(\"San Francisco\",37.7749,-122.4194),\n",
    "    (\"London\",51.5072,-0.1276),(\"Berlin\",52.52,13.405),(\"Nairobi\", -1.286389,36.817223),\n",
    "    (\"Sydney\",-33.8688,151.2093),(\"Bangalore\",12.9716,77.5946),(\"Paris\",48.8566,2.3522),(\"Mexico City\",19.4326,-99.1332)\n",
    "]\n",
    "\n",
    "skill_bank = [\n",
    "    \"python\",\"pytorch\",\"tensorflow\",\"django\",\"react\",\"nextjs\",\"go\",\"kubernetes\",\"aws\",\"gcp\",\n",
    "    \"video editing\",\"storyboarding\",\"scriptwriting\",\"podcasting\",\"seo\",\"branding\",\"figma\",\"design systems\",\n",
    "    \"statistics\",\"causal inference\",\"nlp\",\"cv\",\"llm prompting\",\"sql\",\"dbt\",\"airflow\",\n",
    "    \"grant writing\",\"field research\",\"lab techniques\",\"oceanography\",\"genomics\",\"biostatistics\",\n",
    "    \"supply chain\",\"marketing\",\"growth\",\"product\",\"fundraising\",\"strategy\"\n",
    "]\n",
    "interest_bank = [\n",
    "    \"ocean conservation\",\"coral reef restoration\",\"climate tech\",\"educational apps\",\"healthcare AI\",\n",
    "    \"creator economy\",\"open source tools\",\"social impact\",\"rural connectivity\",\"financial inclusion\",\n",
    "    \"short-form video\",\"long-form YouTube\",\"beauty brand\",\"lipstick R&D\",\"fashion sustainability\",\n",
    "    \"music production\",\"publishing\",\"newsletter growth\",\"sports analytics\",\"mental health\",\n",
    "    \"language learning\",\"VR social spaces\",\"next social network\",\"privacy-first messaging\"\n",
    "]\n",
    "\n",
    "goals_examples = [\n",
    "    \"launch a YouTube channel teaching ML from scratch\",\n",
    "    \"build low-cost sensors to monitor microplastics in rivers\",\n",
    "    \"create a community-powered social network with better moderation\",\n",
    "    \"start a cruelty-free lipstick brand with transparent supply chain\",\n",
    "    \"develop AI tools for writers to plan book outlines\",\n",
    "    \"spin up an educational game for climate science\",\n",
    "    \"ship a mobile app to connect volunteers with ocean NGOs\",\n",
    "    \"build a data pipeline for grassroots health clinics\",\n",
    "    \"open-source a toolkit for video creators to analyze audience retention\",\n",
    "    \"prototype a privacy-first group chat app with local-first sync\"\n",
    "]\n",
    "\n",
    "def rand_words(pool, kmin, kmax):\n",
    "    k = random.randint(kmin, kmax)\n",
    "    return \", \".join(random.sample(pool, k))\n",
    "\n",
    "def make_answer(topic, city_name):\n",
    "    # create a 120-220 word blurb to stay under 250\n",
    "    options = [\n",
    "        f\"I’m based in {city_name}, balancing work with weekend projects. I care about impact and craft. Outside of work I run, film short videos, and try new recipes. I mentor juniors and love pairing.\",\n",
    "        f\"In {city_name}, I split time between creative work and tinkering. I sketch interfaces, read research papers, and test prototypes with friends. I’m energized by small teams shipping useful things.\",\n",
    "        f\"{city_name} is home. I keep a simple routine: work, exercise, cook, dog park. Evenings go to side projects where I learn new stacks and collaborate with people who care about ethics and accessibility.\"\n",
    "    ]\n",
    "    txt = random.choice(options)\n",
    "    return txt\n",
    "\n",
    "records = []\n",
    "for i, name in enumerate(names, start=1):\n",
    "    role = random.choice(roles)\n",
    "    city, lat, lon = random.choice(cities)\n",
    "    years = random.randint(1, 15)\n",
    "    skills = rand_words(skill_bank, 3, 7)\n",
    "    interests = rand_words(interest_bank, 3, 7)\n",
    "    human = make_answer(\"human\", city)\n",
    "    professional = f\"I work as a {role.lower()} with {years} years in the field. Core skills: {skills}. I’ve contributed to projects ranging from prototypes to production launches. Recently, I focused on {random.choice(interest_bank)}. I can produce clear docs, stable code or creative assets, and collaborate across functions.\"\n",
    "    contributor = \"I like async collaboration with tight feedback loops. I write short design docs, propose milestones, demo weekly, and keep a calm tempo. I value psychological safety and clear ownership. I bring reliability, curiosity, and momentum.\"\n",
    "    interests_long = f\"My current goals: {random.choice(goals_examples)}. I’m excited about teaming up with people who value craft and mission. I enjoy learning adjacent domains and sharing knowledge in the open.\"\n",
    "    reason = random.choice([\"Expand network\",\"Find collaborators\",\"Find projects\",\"Build a dream\"])\n",
    "    answers = dict(\n",
    "        human=human, role=role, interests=interests, skills=skills, years_exp=str(years),\n",
    "        professional=professional, contributor=contributor, interests_long=interests_long, reason=reason\n",
    "    )\n",
    "    norm = normalize_interview(answers)\n",
    "    # random TIPI\n",
    "    tipi = [random.randint(2,6) for _ in range(10)]\n",
    "    bf = score_tipi(tipi)\n",
    "    records.append(dict(\n",
    "        user_id=i, name=name, role=norm[\"role\"], interests=norm[\"interests\"], skills=norm[\"skills\"],\n",
    "        years_exp=norm[\"years_exp\"], bio=norm[\"bio\"], reason_for_joining=norm[\"reason_for_joining\"],\n",
    "        long_text=norm[\"long_text\"], lat=lat, lon=lon, bf=bf\n",
    "    ))\n",
    "\n",
    "users = pd.DataFrame(records)\n",
    "users.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847835d",
   "metadata": {},
   "source": [
    "## Build similarity signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eaf072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Text\n",
    "vec, X_text = build_text_matrix(users)\n",
    "S_text = cosine_similarity(X_text)\n",
    "S_text = (S_text - S_text.min())/(S_text.max()-S_text.min()+1e-9)\n",
    "\n",
    "# Geo, Exp, Role\n",
    "S_geo = geo_similarity(users)\n",
    "S_exp = experience_compatibility(users['years_exp'].tolist())\n",
    "S_role = role_complementarity(users)\n",
    "S_content = combine_content(S_text, S_geo, S_exp, S_role)\n",
    "\n",
    "# Skills\n",
    "S_skills_sim = similar_skills_matrix(users)\n",
    "S_skills_comp = complementary_skills_matrix(users)\n",
    "\n",
    "# CF from synthetic likes (sparse)\n",
    "n = len(users)\n",
    "R = np.zeros((n,n), dtype=float)\n",
    "# generate a few random edges conditioned on role proximity to simulate behavior\n",
    "for _ in range(140):\n",
    "    u = random.randrange(n); v = random.randrange(n)\n",
    "    if u==v: continue\n",
    "    # bias: founders like engineers/designers; creators like writers/designers\n",
    "    if users.iloc[u].role==\"Founder\" and users.iloc[v].role in [\"Engineer\",\"Designer\"]: R[u,v]=1.0\n",
    "    elif users.iloc[u].role==\"Creator\" and users.iloc[v].role in [\"Writer\",\"Designer\",\"Engineer\"]: R[u,v]=1.0\n",
    "    elif random.random() < 0.08: R[u,v]=1.0\n",
    "S_cf = cosine_similarity(R.T); \n",
    "S_cf = (S_cf - S_cf.min())/(S_cf.max()-S_cf.min()+1e-9)\n",
    "\n",
    "# Graph PPR on directed likes\n",
    "G = nx.DiGraph(); G.add_nodes_from(users['user_id'].tolist())\n",
    "edges = [(int(users.iloc[u].user_id), int(users.iloc[v].user_id)) for u in range(n) for v in range(n) if R[u,v]>0]\n",
    "G.add_edges_from(edges)\n",
    "nodes = sorted(G.nodes()); idx = {u:i for i,u in enumerate(nodes)}\n",
    "S_graph = np.zeros((n,n))\n",
    "for u in nodes:\n",
    "    # restart prob 0.2\n",
    "    pr = nx.pagerank(G, alpha=0.8, personalization={k:(1.0 if k==u else 0.0) for k in nodes})\n",
    "    for v,s in pr.items(): S_graph[idx[u], idx[v]] = s\n",
    "S_graph = (S_graph - S_graph.min())/(S_graph.max()-S_graph.min()+1e-12)\n",
    "\n",
    "# Personality cosine\n",
    "S_person = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if i==j: continue\n",
    "        S_person[i,j] = bigfive_cosine(users.iloc[i].bf, users.iloc[j].bf)\n",
    "S_person = (S_person - S_person.min())/(S_person.max()-S_person.min()+1e-9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6cbd87",
   "metadata": {},
   "source": [
    "## Final fusion & examples (skills_mode toggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "659831d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def top_matches_for(idx: int, skills_mode=\"similar\", k=3):\n",
    "    S_sk = S_skills_sim if skills_mode==\"similar\" else S_skills_comp\n",
    "    S_final = fuse_scores(S_content, S_cf, S_graph, S_person, S_sk)\n",
    "    picks = mmr(idx, S_final, K=k, lambda_rel=0.7)\n",
    "    cols = ['user_id','name','role','interests','skills','years_exp','reason_for_joining']\n",
    "    return users.iloc[picks][cols].assign(score=[S_final[idx,j] for j in picks])\n",
    "\n",
    "# Show for a few seed users under both modes\n",
    "sample_idx = [0, 7, 13, 25, 42]  # five examples\n",
    "demo = {}\n",
    "for i in sample_idx:\n",
    "    user_name = users.iloc[i][\"name\"]  # correctly extract the 'name' field\n",
    "    demo[f\"{user_name} (similar)\"] = top_matches_for(i, \"similar\", 3)\n",
    "    demo[f\"{user_name} (complementary)\"] = top_matches_for(i, \"complementary\", 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2d5683",
   "metadata": {},
   "source": [
    "## Mutual-best pairs (greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5027bf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(4, 8, 0.9288345873777559),\n",
       "  (18, 41, 0.9230267340344829),\n",
       "  (11, 17, 0.8695613236621874),\n",
       "  (21, 44, 0.8594220381547211),\n",
       "  (30, 34, 0.8581288725157666)],\n",
       " [(30, 34, 0.8581288725157666),\n",
       "  (4, 8, 0.835936991607384),\n",
       "  (7, 18, 0.7878725733706853),\n",
       "  (12, 13, 0.7780358271203902),\n",
       "  (16, 17, 0.762738444858308)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def mutual_best_pairs(skills_mode=\"similar\"):\n",
    "    S_sk = S_skills_sim if skills_mode==\"similar\" else S_skills_comp\n",
    "    S_final = fuse_scores(S_content, S_cf, S_graph, S_person, S_sk)\n",
    "    n = S_final.shape[0]\n",
    "    best = {i:int(np.argmax(S_final[i,:] + (np.arange(n)==i)*-1e9)) for i in range(n)}\n",
    "    used=set(); pairs=[]\n",
    "    for i in range(n):\n",
    "        if i in used: continue\n",
    "        j = best[i]\n",
    "        if j!=i and best.get(j)==i and j not in used:\n",
    "            pairs.append((i,j,float(S_final[i,j])))\n",
    "            used.add(i); used.add(j)\n",
    "    return [(users.iloc[i].name, users.iloc[j].name, score) for i,j,score in sorted(pairs, key=lambda x: -x[2])]\n",
    "\n",
    "pairs_sim = mutual_best_pairs(\"similar\")[:15]\n",
    "pairs_comp = mutual_best_pairs(\"complementary\")[:15]\n",
    "pairs_sim[:5], pairs_comp[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e712d3",
   "metadata": {},
   "source": [
    "## Summary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7652702d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>role</th>\n",
       "      <th>years_exp</th>\n",
       "      <th>city_lat</th>\n",
       "      <th>city_lon</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User01</td>\n",
       "      <td>Designer</td>\n",
       "      <td>7</td>\n",
       "      <td>37.774900</td>\n",
       "      <td>-122.419400</td>\n",
       "      <td>Find collaborators</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User02</td>\n",
       "      <td>Writer</td>\n",
       "      <td>1</td>\n",
       "      <td>-33.868800</td>\n",
       "      <td>151.209300</td>\n",
       "      <td>Find collaborators</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User03</td>\n",
       "      <td>Researcher</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.286389</td>\n",
       "      <td>36.817223</td>\n",
       "      <td>Find collaborators</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User04</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.286389</td>\n",
       "      <td>36.817223</td>\n",
       "      <td>Build a dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User05</td>\n",
       "      <td>Founder</td>\n",
       "      <td>13</td>\n",
       "      <td>51.507200</td>\n",
       "      <td>-0.127600</td>\n",
       "      <td>Find projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>User06</td>\n",
       "      <td>Founder</td>\n",
       "      <td>14</td>\n",
       "      <td>12.971600</td>\n",
       "      <td>77.594600</td>\n",
       "      <td>Build a dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>User07</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>6</td>\n",
       "      <td>40.712800</td>\n",
       "      <td>-74.006000</td>\n",
       "      <td>Find projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>User08</td>\n",
       "      <td>Founder</td>\n",
       "      <td>2</td>\n",
       "      <td>37.774900</td>\n",
       "      <td>-122.419400</td>\n",
       "      <td>Find projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>User09</td>\n",
       "      <td>Designer</td>\n",
       "      <td>10</td>\n",
       "      <td>51.507200</td>\n",
       "      <td>-0.127600</td>\n",
       "      <td>Find projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>User10</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>10</td>\n",
       "      <td>12.971600</td>\n",
       "      <td>77.594600</td>\n",
       "      <td>Find collaborators</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name        role  years_exp   city_lat    city_lon              reason\n",
       "0  User01    Designer          7  37.774900 -122.419400  Find collaborators\n",
       "1  User02      Writer          1 -33.868800  151.209300  Find collaborators\n",
       "2  User03  Researcher          8  -1.286389   36.817223  Find collaborators\n",
       "3  User04   Scientist         10  -1.286389   36.817223       Build a dream\n",
       "4  User05     Founder         13  51.507200   -0.127600       Find projects\n",
       "5  User06     Founder         14  12.971600   77.594600       Build a dream\n",
       "6  User07    Engineer          6  40.712800  -74.006000       Find projects\n",
       "7  User08     Founder          2  37.774900 -122.419400       Find projects\n",
       "8  User09    Designer         10  51.507200   -0.127600       Find projects\n",
       "9  User10    Engineer         10  12.971600   77.594600  Find collaborators"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"name\": users[\"name\"],\n",
    "    \"role\": users[\"role\"],\n",
    "    \"years_exp\": users[\"years_exp\"],\n",
    "    \"city_lat\": users[\"lat\"],\n",
    "    \"city_lon\": users[\"lon\"],\n",
    "    \"reason\": users[\"reason_for_joining\"],\n",
    "})\n",
    "summary.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9bcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
