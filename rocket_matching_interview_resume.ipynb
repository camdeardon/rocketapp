{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3375504a",
   "metadata": {},
   "source": [
    "\n",
    "# Rocket Matching — Interview + Resume Ingestion (Role/Interests/Skills/YearsExp)\n",
    "\n",
    "This notebook extends the hybrid matcher by:\n",
    "- Capturing **role, interests, skills, years_exp** during the interview\n",
    "- **Resume ingestion** (PDF/DOCX) → text extraction → interests/skills/orgs enrichment\n",
    "- Merging interview and resume signals with **confidence weighting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a6baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install numpy pandas scikit-learn networkx geopy spacy keybert sentence-transformers scipy pdfplumber python-docx\n",
    "# !python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c8983c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, pandas as pd, os\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "import importlib\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545bee69",
   "metadata": {},
   "source": [
    "## 1) Interview schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a43ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INTERVIEW_QUESTIONS = {\n",
    "    \"human\": \"Tell me about yourself: age range, city/country, lifestyle, hobbies, pets.\",\n",
    "    \"role\": \"What best describes your role (Founder, Engineer, Designer, Researcher, etc.)?\",\n",
    "    \"interests\": \"List a few interests (comma-separated).\",\n",
    "    \"skills\": \"List your key skills (comma-separated).\",\n",
    "    \"years_exp\": \"How many years of professional experience? (integer)\",\n",
    "    \"professional\": \"Notable employers/clients and things you can produce?\",\n",
    "    \"contributor\": \"How do you like to work? Past projects? What do you bring?\",\n",
    "    \"reason\": \"Why are you joining Rocket? (Expand network, find projects, collaborators, build a dream...)\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a2a06",
   "metadata": {},
   "source": [
    "## 2) Resume ingestion utils (PDF/DOCX → text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db437bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_pdf_text(file_path: str) -> str:\n",
    "    try:\n",
    "        import pdfplumber\n",
    "    except Exception:\n",
    "        raise ImportError(\"pdfplumber not installed. pip install pdfplumber\")\n",
    "    text = []\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            try:\n",
    "                text.append(page.extract_text() or \"\")\n",
    "            except Exception:\n",
    "                continue\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def read_docx_text(file_path: str) -> str:\n",
    "    try:\n",
    "        import docx\n",
    "    except Exception:\n",
    "        raise ImportError(\"python-docx not installed. pip install python-docx\")\n",
    "    doc = docx.Document(file_path)\n",
    "    return \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "\n",
    "def read_resume_text(file_path: Optional[str]) -> str:\n",
    "    if not file_path:\n",
    "        return \"\"\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        return read_pdf_text(file_path)\n",
    "    if ext == \".docx\":\n",
    "        return read_docx_text(file_path)\n",
    "    raise ValueError(\"Unsupported resume type. Please upload .pdf or .docx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3c8bf1",
   "metadata": {},
   "source": [
    "## 3) NLP extraction (spaCy + KeyBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226743e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_loaded_spacy():\n",
    "    if importlib.util.find_spec(\"spacy\") is None:\n",
    "        raise ImportError(\"spaCy not installed. Run: pip install spacy && python -m spacy download en_core_web_sm\")\n",
    "    import spacy\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"spaCy model not found. Run: python -m spacy download en_core_web_sm\") from e\n",
    "    return nlp\n",
    "\n",
    "def ensure_loaded_keybert():\n",
    "    if importlib.util.find_spec(\"keybert\") is None:\n",
    "        raise ImportError(\"KeyBERT not installed. Run: pip install keybert sentence-transformers\")\n",
    "    from keybert import KeyBERT\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    return KeyBERT(model=SentenceTransformer(\"all-MiniLM-L6-v2\"))\n",
    "\n",
    "def extract_fields_from_text(text: str, top_k=15):\n",
    "    nlp = ensure_loaded_spacy()\n",
    "    kw_model = ensure_loaded_keybert()\n",
    "    doc = nlp(text)\n",
    "\n",
    "    locations = [ent.text for ent in doc.ents if ent.label_ in {\"GPE\",\"LOC\"}]\n",
    "    orgs = [ent.text for ent in doc.ents if ent.label_ in {\"ORG\"}]\n",
    "\n",
    "    kp = kw_model.extract_keywords(\n",
    "        text, keyphrase_ngram_range=(1,3), stop_words=\"english\",\n",
    "        top_n=top_k, use_mmr=True, diversity=0.6\n",
    "    )\n",
    "    keyphrases = [k for k,_ in kp]\n",
    "\n",
    "    skills = [k for k in keyphrases if any(s in k.lower() for s in [\n",
    "        \"python\",\"ml\",\"machine learning\",\"nlp\",\"design\",\"product\",\"kubernetes\",\"aws\",\n",
    "        \"go\",\"django\",\"pytorch\",\"data\",\"ux\",\"branding\",\"marketing\",\"growth\",\"strategy\",\"react\",\"sql\"\n",
    "    ])]\n",
    "    interests = [k for k in keyphrases if k not in skills]\n",
    "\n",
    "    def dedupe(seq):\n",
    "        out = []\n",
    "        for x in seq:\n",
    "            if x not in out: out.append(x)\n",
    "        return out\n",
    "\n",
    "    return {\n",
    "        \"locations\": dedupe(locations),\n",
    "        \"orgs\": dedupe(orgs),\n",
    "        \"skills\": dedupe(skills)[:20],\n",
    "        \"interests\": dedupe(interests)[:20],\n",
    "        \"keyphrases\": keyphrases\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c2289",
   "metadata": {},
   "source": [
    "## 4) Interview normalizer + resume merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39a42823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_comma_list(s: str) -> List[str]:\n",
    "    return [x.strip() for x in (s or \"\").split(\",\") if x.strip()]\n",
    "\n",
    "def normalize_interview(answers: Dict[str,str]) -> Dict[str,Any]:\n",
    "    out = {\n",
    "        \"role\": answers.get(\"role\",\"\").strip() or \"Undecided\",\n",
    "        \"interests\": \", \".join(parse_comma_list(answers.get(\"interests\",\"\"))[:20]),\n",
    "        \"skills\": \", \".join(parse_comma_list(answers.get(\"skills\",\"\"))[:20]),\n",
    "        \"years_exp\": int(str(answers.get(\"years_exp\",\"0\")).strip() or 0),\n",
    "        \"bio\": (answers.get(\"professional\",\"\") or \"\")[:200],\n",
    "        \"reason_for_joining\": (answers.get(\"reason\",\"\") or \"\").strip()\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def merge_interview_resume(interview: Dict[str,Any], resume_text: str):\n",
    "    extracted = extract_fields_from_text(resume_text) if resume_text else {\"skills\":[], \"interests\":[], \"locations\":[], \"orgs\":[], \"keyphrases\":[]}\n",
    "    i_skills = parse_comma_list(interview.get(\"skills\",\"\"))\n",
    "    r_skills = extracted.get(\"skills\", [])\n",
    "    i_interests = parse_comma_list(interview.get(\"interests\",\"\"))\n",
    "    r_interests = extracted.get(\"interests\", [])\n",
    "\n",
    "    skills = list(dict.fromkeys(i_skills + r_skills))\n",
    "    interests = list(dict.fromkeys(i_interests + r_interests))\n",
    "\n",
    "    merged = dict(interview)\n",
    "    merged.update({\n",
    "        \"skills\": \", \".join(skills[:20]),\n",
    "        \"interests\": \", \".join(interests[:20]),\n",
    "        \"resume_locations\": extracted.get(\"locations\", []),\n",
    "        \"resume_orgs\": extracted.get(\"orgs\", []),\n",
    "        \"resume_keyphrases\": extracted.get(\"keyphrases\", [])\n",
    "    })\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c9619",
   "metadata": {},
   "source": [
    "## 5) Demo usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882b8566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Engineer',\n",
       " 'interests': 'creator tools, healthcare AI, community projects, open source',\n",
       " 'skills': 'python, django, react, aws, ml, data',\n",
       " 'years_exp': 6,\n",
       " 'bio': 'Built recommender POCs and full‑stack MVPs; ex‑fintech.',\n",
       " 'reason_for_joining': 'Find collaborators and expand my network',\n",
       " 'resume_locations': [],\n",
       " 'resume_orgs': [],\n",
       " 'resume_keyphrases': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "demo_answers = {\n",
    "    \"human\": \"32, Toronto; runs & cooks; has a dog.\",\n",
    "    \"role\": \"Engineer\",\n",
    "    \"interests\": \"creator tools, healthcare AI, community projects, open source\",\n",
    "    \"skills\": \"python, django, react, aws, ml, data\",\n",
    "    \"years_exp\": \"6\",\n",
    "    \"professional\": \"Built recommender POCs and full‑stack MVPs; ex‑fintech.\",\n",
    "    \"contributor\": \"Async, milestone‑driven; I bring velocity and reliability.\",\n",
    "    \"reason\": \"Find collaborators and expand my network\"\n",
    "}\n",
    "\n",
    "resume_path = None  # set to '/mnt/data/resume.pdf' or '/mnt/data/resume.docx' if you upload one\n",
    "resume_text = read_resume_text(resume_path) if resume_path else \"\"\n",
    "interview_norm = normalize_interview(demo_answers)\n",
    "merged_profile = merge_interview_resume(interview_norm, resume_text)\n",
    "merged_profile\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
